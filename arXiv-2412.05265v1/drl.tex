%\documentclass{article}
\documentclass{book}
\usepackage{fullpage}

\newcommand{\textdir}{../..}

\newcommand{\tmpc}{\text{MPC}}
\newcommand{\treplay}{\text{replay}}
\newcommand{\tnew}{\text{new}}
\newcommand{\topt}{\text{opt}}
\newcommand{\wnew}{\vw_{\tnew}}


\setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}

\input{packages}
\input{macros}

%    \newcommand{\figdir}{\textdir/figures} 
%    \newcommand{\figtype}{png} 

% for biblatex
\addbibresource{\textdir/bib,\textdir/bib2}


\begin{document}


\title{Reinforcement Learning: An Overview\footnote{
  Parts of this monograph
  are borrowed from chapters 34 and 35 of my textbook \citep{book2}.
  However, I have  added a lot of new material,
  so this text supercedes those chapters.
  Thanks to Lihong Li,
  who wrote 
  \cref{sec:imitation}
  and parts of \cref{sec:exploreExploit},
  and Pablo Samuel Castro,
  who  proof-read a draft of this manuscript.
}
}
\author{Kevin P. Murphy}
\date{\today}
\maketitle

\tableofcontents



%https://mandi-zhao.gitbook.io/deeprl-notes
%https://www.reddit.com/r/reinforcementlearning/comments/17w1efb/book_recommendation_reinforcement_learning_for/?rdt=42655

%\input{intro}
%\input{value-rl}
%\input{policy-rl}
%\input{model-rl}
%\input{successor}
%\input{other-rl}


%\eat{
% \input{intro}
\input{value-rl}
% \input{policy-rl}
% \input{model-rl}
% \input{successor}
% \input{other-rl}
%}


\printbibliography 
\end{document}



